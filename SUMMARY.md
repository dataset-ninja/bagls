**BAGLS: Benchmark for Automatic Glottis Segmentation (Images)** is a dataset for semantic segmentation and object detection tasks. It is used in the medical industry. 

The dataset consists of 59250 images with 55286 labeled objects belonging to 1 single class (*glottis*).

Images in the BAGLS: Images dataset have pixel-level semantic segmentation annotations. There are 3964 (7% of the total) unlabeled images (i.e. without annotations). There are 2 splits in the dataset: *train* (55750 images) and *test* (3500 images). Alternatively, the dataset could be split into 2 sexes: ***woman*** (40600 images) and ***man*** (16050 images). Additionally, every image contains information about patients ***age range***, glottis state ***status***. Moreover, every image is tagged with ***video id***. The dataset was released in 2020 by the the GER-US-BEL joint research group.

<img src="https://github.com/dataset-ninja/bagls/raw/main/visualizations/poster.png">
